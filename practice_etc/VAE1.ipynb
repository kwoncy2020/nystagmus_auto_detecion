{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbdda83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "number of blink_lt_imgs :  1181\n",
      "train_val 1 shape : (944, 240, 320) (237, 240, 320) (944, 240, 320) (237, 240, 320)\n",
      "number of blink_rt_imgs :  1223\n",
      "train_val 2 shape : (978, 240, 320) (245, 240, 320) (978, 240, 320) (245, 240, 320)\n",
      "number of non_blink_lt_imgs :  1181\n",
      "train_val 3 shape : (944, 240, 320) (237, 240, 320) (944, 240, 320) (237, 240, 320)\n",
      "number of non_blink_rt_imgs :  1223\n",
      "train_val 4 shaep : (978, 240, 320) (245, 240, 320) (978, 240, 320) (245, 240, 320)\n",
      "total of train_val : (3844, 240, 320) (964, 240, 320) (3844, 240, 320) (964, 240, 320)\n",
      "loading times : 317.741708278656\n"
     ]
    }
   ],
   "source": [
    "from configparser import ConfigParser\n",
    "import glob, os, cv2\n",
    "from pandas import StringDtype\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from pickletools import optimize\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD,RMSprop\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# from draw_ellipse import *\n",
    "# from ellipses import *\n",
    "# from bwperim import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2,3'\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# BASE_PATH = \"C:/kwoncy/eye/temp_xml/pair/data_sets/eye2\"\n",
    "BASE_PATH_NONBLINK = \"./new_data_sets/eye_nonblink\"\n",
    "BASE_PATH_BLINK = \"./new_data_sets/eye_blink\"\n",
    "img_height = 240\n",
    "img_width = 320\n",
    "FX = 2\n",
    "FY = 2\n",
    "SEED = 555\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "blink_lt_original_paths = sorted(glob.glob(BASE_PATH_BLINK + '/Lt.original/*.png'))\n",
    "n_blink_lt_imgs = len(blink_lt_original_paths)\n",
    "print(\"number of blink_lt_imgs : \", n_blink_lt_imgs)\n",
    "imgs_lt_original_blink = np.stack([ cv2.imread(f'{BASE_PATH_BLINK}/Lt.original/{i}.png',0) for i in range(n_blink_lt_imgs)])\n",
    "imgs_lt_original_blink = imgs_lt_original_blink.astype('float32') / 255.\n",
    "\n",
    "masks_lt_pupil_blink = np.stack([ cv2.imread(f'{BASE_PATH_BLINK}/Lt.pupil/{i}.png',0) for i in range(n_blink_lt_imgs)])\n",
    "masks_lt_pupil_blink = masks_lt_pupil_blink.astype('float32') / 255.\n",
    "\n",
    "imgs_train1, imgs_val1, masks_train1, masks_val1 = train_test_split(imgs_lt_original_blink,masks_lt_pupil_blink,test_size=0.2, shuffle=True, random_state=SEED)\n",
    "print(\"train_val 1 shape :\", imgs_train1.shape, imgs_val1.shape, masks_train1.shape, masks_val1.shape)\n",
    "\n",
    "\n",
    "blink_rt_original_paths = sorted(glob.glob(BASE_PATH_BLINK + '/Rt.original/*.png'))\n",
    "n_blink_rt_imgs = len(blink_rt_original_paths)\n",
    "print(\"number of blink_rt_imgs : \", n_blink_rt_imgs)\n",
    "imgs_rt_original_blink = np.stack([ cv2.imread(f'{BASE_PATH_BLINK}/Rt.original/{i}.png',0) for i in range(n_blink_rt_imgs)])\n",
    "imgs_rt_original_blink = imgs_rt_original_blink.astype('float32') / 255.\n",
    "\n",
    "masks_rt_pupil_blink = np.stack([ cv2.imread(f'{BASE_PATH_BLINK}/Rt.pupil/{i}.png',0) for i in range(n_blink_rt_imgs)])\n",
    "masks_rt_pupil_blink = masks_rt_pupil_blink.astype('float32') / 255.\n",
    "\n",
    "imgs_train2, imgs_val2, masks_train2, masks_val2 = train_test_split(imgs_rt_original_blink,masks_rt_pupil_blink,test_size=0.2, shuffle=True, random_state=SEED)\n",
    "print(\"train_val 2 shape :\", imgs_train2.shape, imgs_val2.shape, masks_train2.shape, masks_val2.shape)\n",
    "\n",
    "\n",
    "non_blink_lt_original_paths = sorted(glob.glob(BASE_PATH_NONBLINK + '/Lt.original/*.png'))\n",
    "n_non_blink_lt_imgs = len(non_blink_lt_original_paths)\n",
    "\n",
    "l_rand_lt_index = np.random.RandomState(seed = SEED).choice(n_non_blink_lt_imgs, n_blink_lt_imgs, replace=False)\n",
    "print(\"number of non_blink_lt_imgs : \", len(l_rand_lt_index))\n",
    "\n",
    "imgs_lt_original_non_blink = np.stack([ cv2.imread(f'{BASE_PATH_NONBLINK}/Lt.original/{i}.png',0) for i in l_rand_lt_index])\n",
    "imgs_lt_original_non_blink = imgs_lt_original_non_blink.astype('float32') / 255.\n",
    "\n",
    "masks_lt_pupil_non_blink = np.stack([ cv2.imread(f'{BASE_PATH_NONBLINK}/Lt.pupil/{i}.png',0) for i in l_rand_lt_index])\n",
    "masks_lt_pupil_non_blink = masks_lt_pupil_non_blink.astype('float32') / 255.\n",
    "\n",
    "imgs_train3, imgs_val3, masks_train3, masks_val3 = train_test_split(imgs_lt_original_non_blink,masks_lt_pupil_non_blink,test_size=0.2, shuffle=True, random_state=SEED)\n",
    "print(\"train_val 3 shape :\", imgs_train3.shape, imgs_val3.shape, masks_train3.shape, masks_val3.shape)\n",
    "\n",
    "\n",
    "non_blink_rt_original_paths = sorted(glob.glob(BASE_PATH_NONBLINK + '/Rt.original/*.png'))\n",
    "n_non_blink_rt_imgs = len(non_blink_rt_original_paths)\n",
    "\n",
    "l_rand_rt_index = np.random.RandomState(seed = SEED).choice(n_non_blink_rt_imgs, n_blink_rt_imgs, replace=False)\n",
    "print(\"number of non_blink_rt_imgs : \", len(l_rand_rt_index))\n",
    "\n",
    "imgs_rt_original_non_blink = np.stack([ cv2.imread(f'{BASE_PATH_NONBLINK}/Rt.original/{i}.png',0) for i in l_rand_rt_index])\n",
    "imgs_rt_original_non_blink = imgs_rt_original_non_blink.astype('float32') / 255.\n",
    "\n",
    "masks_rt_pupil_non_blink = np.stack([ cv2.imread(f'{BASE_PATH_NONBLINK}/Rt.pupil/{i}.png',0) for i in l_rand_rt_index])\n",
    "masks_rt_pupil_non_blink = masks_rt_pupil_non_blink.astype('float32') / 255.\n",
    "\n",
    "\n",
    "imgs_train4, imgs_val4, masks_train4, masks_val4 = train_test_split(imgs_rt_original_non_blink,masks_rt_pupil_non_blink,test_size=0.2, shuffle=True, random_state=SEED)\n",
    "print(\"train_val 4 shaep :\", imgs_train4.shape, imgs_val4.shape, masks_train4.shape, masks_val4.shape)\n",
    "\n",
    "\n",
    "imgs_train_whole = np.concatenate([imgs_train1, imgs_train2, imgs_train3, imgs_train4], axis=0)\n",
    "imgs_val_whole = np.concatenate([imgs_val1, imgs_val2, imgs_val3, imgs_val4], axis=0)\n",
    "masks_train_whole = np.concatenate([masks_train1, masks_train2, masks_train3, masks_train4], axis=0)\n",
    "masks_val_whole = np.concatenate([masks_val1, masks_val2, masks_val3, masks_val4], axis=0)\n",
    "\n",
    "# imgs_train_whole = np.concatenate([imgs_train3, imgs_train4], axis=0)\n",
    "# imgs_val_whole = np.concatenate([imgs_val3, imgs_val4], axis=0)\n",
    "# masks_train_whole = np.concatenate([masks_train3, masks_train4], axis=0)\n",
    "# masks_val_whole = np.concatenate([masks_val3, masks_val4], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(\"total of train_val :\", imgs_train_whole.shape, imgs_val_whole.shape, masks_train_whole.shape, masks_val_whole.shape)\n",
    "time_end = time.time()\n",
    "print(\"loading times :\", time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1561c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val_flip1 :  (7688, 240, 320) (1928, 240, 320) (7688, 240, 320) (1928, 240, 320)\n",
      "loading times : 2.295642852783203\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "imgs_train_flip1 = imgs_train_whole[:,:,-1::-1].copy()\n",
    "imgs_val_flip1 = imgs_val_whole[:,:,-1::-1].copy()\n",
    "masks_train_flip1 = masks_train_whole[:,:,-1::-1].copy()\n",
    "masks_val_flip1 = masks_val_whole[:,:,-1::-1].copy()\n",
    "\n",
    "imgs_train_concat1 = np.concatenate([imgs_train_whole, imgs_train_flip1], axis=0)\n",
    "imgs_val_concat1 = np.concatenate([imgs_val_whole, imgs_val_flip1], axis=0)\n",
    "masks_train_concat1 = np.concatenate([masks_train_whole, masks_train_flip1], axis=0)\n",
    "masks_val_concat1 = np.concatenate([masks_val_whole, masks_val_flip1], axis=0)\n",
    "\n",
    "print(\"train_val_flip1 : \", imgs_train_concat1.shape, imgs_val_concat1.shape, masks_train_concat1.shape, masks_val_concat1.shape)\n",
    "\n",
    "# imgs_train_flip2 = imgs_train_concat1[:,-1::-1,:].copy()\n",
    "# imgs_val_flip2 = imgs_val_concat1[:,-1::-1,:].copy()\n",
    "# masks_train_flip2 = masks_train_concat1[:,-1::-1,:].copy()\n",
    "# masks_val_flip2 = masks_val_concat1[:,-1::-1,:].copy()\n",
    "\n",
    "# imgs_train_concat2 = np.concatenate([imgs_train_concat1, imgs_train_flip2], axis=0)\n",
    "# imgs_val_concat2 = np.concatenate([imgs_val_concat1, imgs_val_flip2], axis=0)\n",
    "# masks_train_concat2 = np.concatenate([masks_train_concat1, masks_train_flip2], axis=0)\n",
    "# masks_val_concat2 = np.concatenate([masks_val_concat1, masks_val_flip2], axis=0)\n",
    "\n",
    "# print(\"train_val_flip2 : \", imgs_train_concat2.shape, imgs_val_concat2.shape, masks_train_concat2.shape, masks_val_concat2.shape)\n",
    "\n",
    "imgs_train = imgs_train_concat1\n",
    "imgs_val = imgs_val_concat1\n",
    "masks_train = masks_train_concat1\n",
    "masks_val = masks_val_concat1\n",
    "\n",
    "time_end = time.time()\n",
    "print(\"loading times :\", time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6526d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f412f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VAE_DIM = 30 * 40\n",
    "INTERMEDIATE_DIM = 64\n",
    "LATENT_DIM = 2\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], LATENT_DIM), mean=0, stddev=0.1)\n",
    "    \n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "\n",
    "def build_VAE(img_height=240,img_width=320,filters=32,activation='elu',kernel_init='he_uniform'):\n",
    "    FILTERS = filters\n",
    "    ACTIVATION_FN = activation\n",
    "    KERNEL_INIT = kernel_init\n",
    "\n",
    "    \n",
    "    ###### encoder\n",
    "    layer1 = Input(shape = (img_height,img_width,1))\n",
    "    layer2 = Conv2D(filters = FILTERS, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer1)\n",
    "    layer3 = BatchNormalization()(layer2)\n",
    "    layer4 = Activation(ACTIVATION_FN)(layer3)\n",
    "    \n",
    "    layer5 = Conv2D(filters=FILTERS, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer4)\n",
    "    layer6 = BatchNormalization()(layer5)\n",
    "    layer7 = Activation(ACTIVATION_FN)(layer6)\n",
    "    layer8 = Conv2D(filters=FILTERS, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer7)\n",
    "    layer9 = BatchNormalization()(layer8)\n",
    "    layer10 = Add()([layer4,layer9])\n",
    "    layer11 = Activation(ACTIVATION_FN)(layer10)\n",
    "\n",
    "    layer12 = MaxPool2D(strides=(2,2))(layer11)\n",
    "\n",
    "    layer13 = Conv2D(filters=FILTERS *2, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer12)\n",
    "    layer14 = BatchNormalization()(layer13)\n",
    "    layer15 = Activation(ACTIVATION_FN)(layer14)\n",
    "    layer16 = Conv2D(filters=FILTERS *2, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer15)\n",
    "    layer17 = BatchNormalization()(layer16)\n",
    "    layer18 = Add()([layer17,layer13])\n",
    "    layer19 = Activation(ACTIVATION_FN)(layer18)\n",
    "\n",
    "    layer20 = MaxPool2D(strides=(2,2))(layer19)\n",
    "\n",
    "    layer21 = Conv2D(filters=FILTERS *4, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer20)\n",
    "    layer22 = BatchNormalization()(layer21)\n",
    "    layer23 = Activation(ACTIVATION_FN)(layer22)\n",
    "    layer24 = Conv2D(filters=FILTERS *4, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer23)\n",
    "    layer25 = BatchNormalization()(layer24)\n",
    "    layer26 = Add()([layer25,layer21])\n",
    "    layer27 = Activation(ACTIVATION_FN)(layer26)\n",
    "\n",
    "    layer28 = MaxPool2D(strides=(2,2))(layer27)\n",
    "\n",
    "    layer29 = Conv2D(filters=FILTERS *8, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer28)\n",
    "    layer30 = BatchNormalization()(layer29)\n",
    "    layer31 = Activation(ACTIVATION_FN)(layer30) \n",
    "    layer32 = Conv2D(filters=FILTERS *8, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer31)\n",
    "    layer33 = BatchNormalization()(layer32)\n",
    "    layer34 = Add()([layer33,layer29])\n",
    "    layer35 = Activation(ACTIVATION_FN)(layer34)\n",
    "    \n",
    "    flatten1 = Flatten()(layer35)\n",
    "    vae_layer1 = Dense(INTERMEDIATE_DIM)(flatten1)\n",
    "    vae_layer2 = BatchNormalization()(vae_layer1)\n",
    "    vae_layer3 = Activation(ACTIVATION_FN)(vae_layer2)\n",
    "    z_mean = Dense(LATENT_DIM)(vae_layer3)\n",
    "    z_log_sigma= Dense(LATENT_DIM)(vae_layer3)\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "    \n",
    "    encoder = Model(layer1,[z_mean, z_log_sigma, z])\n",
    "    \n",
    "    \n",
    "    #### decoder\n",
    "    latent_inputs = Input(shape=(LATENT_DIM,))\n",
    "    x = Dense(INTERMEDIATE_DIM, name='decoder_dense1')(latent_inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(ACTIVATION_FN)(x)\n",
    "    x = Dense(INPUT_VAE_DIM, name='decoder_dense2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(ACTIVATION_FN)(x)\n",
    "#     x = Reshape((layer35.output_shape[1],layer35.output_shape[2]))(x)\n",
    "    x = Reshape((30,40,1))(x)\n",
    "    \n",
    "    x_skip = Conv2D(filters=FILTERS *8, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(x)\n",
    "    x = BatchNormalization()(x_skip)\n",
    "    x = Activation(ACTIVATION_FN)(x)\n",
    "    x = Conv2D(filters=FILTERS *8, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x,x_skip])\n",
    "    x = Activation(ACTIVATION_FN)(x)\n",
    "    \n",
    "    \n",
    "    layer36 = UpSampling2D(size=(2,2))(x)\n",
    "    \n",
    "    layer37 = Conv2D(filters=FILTERS *4, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer36)\n",
    "    layer38 = BatchNormalization()(layer37)\n",
    "    layer39 = Activation(ACTIVATION_FN)(layer38)\n",
    "    layer40 = Conv2D(filters=FILTERS *4, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer39)\n",
    "    layer41 = BatchNormalization()(layer40)\n",
    "    layer42 = Add()([layer37,layer41])\n",
    "    layer43 = Activation(ACTIVATION_FN)(layer42)\n",
    "\n",
    "    layer44 = UpSampling2D(size=(2,2))(layer43)\n",
    "\n",
    "    layer45 = Conv2D(filters=FILTERS *2, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer44)\n",
    "    layer46 = BatchNormalization()(layer45)\n",
    "    layer47 = Activation(ACTIVATION_FN)(layer46)\n",
    "    layer48 = Conv2D(filters=FILTERS *2, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer47)\n",
    "    layer49 = BatchNormalization()(layer48)\n",
    "    layer50 = Add()([layer49,layer45])\n",
    "    layer51 = Activation(ACTIVATION_FN)(layer50)\n",
    "\n",
    "    layer52 = UpSampling2D(size=(2,2))(layer51)\n",
    "\n",
    "    layer53 = Conv2D(filters=FILTERS, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer52)\n",
    "    layer54 = BatchNormalization()(layer53)\n",
    "    layer55 = Activation(ACTIVATION_FN)(layer54)\n",
    "    layer56 = Conv2D(filters=FILTERS, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer55)\n",
    "    layer57 = BatchNormalization()(layer56)\n",
    "    layer58 = Add()([layer57,layer53])\n",
    "    layer59 = Activation(ACTIVATION_FN)(layer58)\n",
    "\n",
    "    layer60 = Conv2D(filters=FILTERS, kernel_size=(3,3), activation=None, kernel_initializer=KERNEL_INIT, padding='same')(layer59)\n",
    "    layer61 = BatchNormalization()(layer60)\n",
    "    layer62 = Activation(ACTIVATION_FN)(layer61)\n",
    "\n",
    "    output_layer = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid', kernel_initializer=KERNEL_INIT, padding='same')(layer61)\n",
    "    \n",
    "    decoder = Model(latent_inputs, output_layer)\n",
    "    \n",
    "    \n",
    "    vae_output = decoder(encoder(layer1)[2])\n",
    "    vae = Model(layer1, vae_output)\n",
    "    \n",
    "#     reconstruction_loss = keras.losses.binary_crossentropy(layer1,vae_output)\n",
    "    reconstruction_loss = keras.losses.mse(layer1,vae_output)\n",
    "    reconstruction_loss *= INPUT_VAE_DIM\n",
    "    kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    \n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    \n",
    "    \n",
    "    return encoder, decoder, vae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d216533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(y_ture, y_pred):\n",
    "    y_true_f = K.flatten(y_ture)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55ec85c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 240, 320, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_15 (Functional)           [(None, 2), (None, 2 20846276    input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_16 (Functional)           (None, 240, 320, 1)  1270193     model_15[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 240, 320, 32) 320         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 240, 320, 32) 128         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 240, 320, 32) 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 240, 320, 32) 9248        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 240, 320, 32) 128         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 240, 320, 32) 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 240, 320, 32) 9248        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 240, 320, 32) 128         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 240, 320, 32) 0           activation_105[0][0]             \n",
      "                                                                 batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 240, 320, 32) 0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 120, 160, 32) 0           activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 120, 160, 64) 18496       max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 120, 160, 64) 256         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 120, 160, 64) 0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 120, 160, 64) 36928       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 120, 160, 64) 256         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 120, 160, 64) 0           batch_normalization_109[0][0]    \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 120, 160, 64) 0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 60, 80, 64)   0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 60, 80, 128)  73856       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 60, 80, 128)  512         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 60, 80, 128)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 60, 80, 128)  147584      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 60, 80, 128)  512         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 60, 80, 128)  0           batch_normalization_111[0][0]    \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 60, 80, 128)  0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 30, 40, 128)  0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 30, 40, 256)  295168      max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 30, 40, 256)  1024        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 30, 40, 256)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 30, 40, 256)  590080      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 30, 40, 256)  1024        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 30, 40, 256)  0           batch_normalization_113[0][0]    \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 30, 40, 256)  0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 307200)       0           activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           19660864    flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 64)           256         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 64)           0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            130         activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2)            130         activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_10 (TFOpLa (None, 2)            0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.square_5 (TFOpLambda)   (None, 2)            0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_11 (TFOpLa (None, 240, 320, 1)  0           model_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_5 (TFOpLambda)          (None, 240, 320, 1)  0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_10 (TFOpLambda (None, 2)            0           tf.__operators__.add_10[0][0]    \n",
      "                                                                 tf.math.square_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp_5 (TFOpLambda)      (None, 2)            0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.squared_difference_2 (T (None, 240, 320, 1)  0           tf.convert_to_tensor_11[0][0]    \n",
      "                                                                 tf.cast_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_11 (TFOpLambda (None, 2)            0           tf.math.subtract_10[0][0]        \n",
      "                                                                 tf.math.exp_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_10 (TFOpLam (None, 240, 320)     0           tf.math.squared_difference_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_5 (TFOpLambd (None,)              0           tf.math.subtract_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_10 (TFOpLambda (None, 240, 320)     0           tf.math.reduce_mean_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_11 (TFOpLambda (None,)              0           tf.math.reduce_sum_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_11 (TFOpLa (None, 240, 320)     0           tf.math.multiply_10[0][0]        \n",
      "                                                                 tf.math.multiply_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_11 (TFOpLam ()                   0           tf.__operators__.add_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_loss_5 (AddLoss)            ()                   0           tf.math.reduce_mean_11[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 22,116,469\n",
      "Trainable params: 22,109,845\n",
      "Non-trainable params: 6,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7688/7688 - 137s - loss: 58.0562 - dice_score: 0.7664\n",
      "Epoch 2/50\n",
      "7688/7688 - 136s - loss: 53.6348 - dice_score: 0.7780\n",
      "Epoch 3/50\n",
      "7688/7688 - 135s - loss: 53.3776 - dice_score: 0.7782\n",
      "Epoch 4/50\n",
      "7688/7688 - 135s - loss: 52.3302 - dice_score: 0.7793\n",
      "Epoch 5/50\n",
      "7688/7688 - 135s - loss: 51.4487 - dice_score: 0.7802\n",
      "Epoch 6/50\n",
      "7688/7688 - 135s - loss: 51.4125 - dice_score: 0.7802\n",
      "Epoch 7/50\n",
      "7688/7688 - 135s - loss: 51.3426 - dice_score: 0.7807\n",
      "Epoch 8/50\n",
      "7688/7688 - 135s - loss: 51.2814 - dice_score: 0.7807\n",
      "Epoch 9/50\n",
      "7688/7688 - 135s - loss: 51.2417 - dice_score: 0.7804\n",
      "Epoch 10/50\n",
      "7688/7688 - 135s - loss: 51.2151 - dice_score: 0.7808\n",
      "Epoch 11/50\n",
      "7688/7688 - 135s - loss: 51.2054 - dice_score: 0.7805\n",
      "Epoch 12/50\n",
      "7688/7688 - 135s - loss: 51.1961 - dice_score: 0.7807\n",
      "Epoch 13/50\n",
      "7688/7688 - 135s - loss: 51.1806 - dice_score: 0.7805\n",
      "Epoch 14/50\n",
      "7688/7688 - 135s - loss: 51.1883 - dice_score: 0.7808\n",
      "Epoch 15/50\n",
      "7688/7688 - 135s - loss: 51.1489 - dice_score: 0.7808\n",
      "Epoch 16/50\n",
      "7688/7688 - 135s - loss: 51.1672 - dice_score: 0.7807\n",
      "Epoch 17/50\n",
      "7688/7688 - 135s - loss: 51.1695 - dice_score: 0.7804\n",
      "Epoch 18/50\n",
      "7688/7688 - 135s - loss: 51.1509 - dice_score: 0.7807\n",
      "Epoch 19/50\n",
      "7688/7688 - 135s - loss: 51.1531 - dice_score: 0.7808\n",
      "Epoch 20/50\n",
      "7688/7688 - 135s - loss: 51.1327 - dice_score: 0.7806\n",
      "Epoch 21/50\n",
      "7688/7688 - 135s - loss: 51.1483 - dice_score: 0.7806\n",
      "Epoch 22/50\n",
      "7688/7688 - 135s - loss: 51.1289 - dice_score: 0.7810\n",
      "Epoch 23/50\n",
      "7688/7688 - 135s - loss: 51.1504 - dice_score: 0.7806\n",
      "Epoch 24/50\n",
      "7688/7688 - 135s - loss: 51.1579 - dice_score: 0.7806\n",
      "Epoch 25/50\n",
      "7688/7688 - 135s - loss: 51.1455 - dice_score: 0.7807\n",
      "Epoch 26/50\n",
      "7688/7688 - 135s - loss: 51.1330 - dice_score: 0.7809\n",
      "Epoch 27/50\n",
      "7688/7688 - 135s - loss: 51.1385 - dice_score: 0.7804\n",
      "Epoch 28/50\n",
      "7688/7688 - 135s - loss: 51.1386 - dice_score: 0.7809\n",
      "Epoch 29/50\n",
      "7688/7688 - 135s - loss: 51.1261 - dice_score: 0.7807\n",
      "Epoch 30/50\n",
      "7688/7688 - 135s - loss: 51.1326 - dice_score: 0.7804\n",
      "Epoch 31/50\n",
      "7688/7688 - 135s - loss: 51.1268 - dice_score: 0.7810\n",
      "Epoch 32/50\n",
      "7688/7688 - 135s - loss: 51.1170 - dice_score: 0.7805\n",
      "Epoch 33/50\n",
      "7688/7688 - 135s - loss: 51.1248 - dice_score: 0.7808\n",
      "Epoch 34/50\n",
      "7688/7688 - 135s - loss: 51.1156 - dice_score: 0.7805\n",
      "Epoch 35/50\n",
      "7688/7688 - 135s - loss: 51.1107 - dice_score: 0.7808\n",
      "Epoch 36/50\n",
      "7688/7688 - 135s - loss: 51.1123 - dice_score: 0.7805\n",
      "Epoch 37/50\n",
      "7688/7688 - 135s - loss: 51.1274 - dice_score: 0.7811\n",
      "Epoch 38/50\n",
      "7688/7688 - 135s - loss: 51.1232 - dice_score: 0.7803\n",
      "Epoch 39/50\n",
      "7688/7688 - 135s - loss: 51.1270 - dice_score: 0.7807\n",
      "Epoch 40/50\n",
      "7688/7688 - 135s - loss: 51.1330 - dice_score: 0.7809\n",
      "Epoch 41/50\n",
      "7688/7688 - 135s - loss: 51.1374 - dice_score: 0.7807\n",
      "Epoch 42/50\n",
      "7688/7688 - 135s - loss: 51.1050 - dice_score: 0.7807\n",
      "Epoch 43/50\n",
      "7688/7688 - 135s - loss: 51.1197 - dice_score: 0.7807\n",
      "Epoch 44/50\n",
      "7688/7688 - 135s - loss: 51.1111 - dice_score: 0.7808\n",
      "Epoch 45/50\n",
      "7688/7688 - 135s - loss: 51.1009 - dice_score: 0.7809\n",
      "Epoch 46/50\n",
      "7688/7688 - 135s - loss: 51.1050 - dice_score: 0.7806\n",
      "Epoch 47/50\n",
      "7688/7688 - 135s - loss: 51.1269 - dice_score: 0.7807\n",
      "Epoch 48/50\n",
      "7688/7688 - 135s - loss: 51.1204 - dice_score: 0.7806\n",
      "Epoch 49/50\n",
      "7688/7688 - 135s - loss: 51.1295 - dice_score: 0.7807\n",
      "Epoch 50/50\n",
      "7688/7688 - 135s - loss: 51.1265 - dice_score: 0.7806\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1831/1357875809.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# scores = model.evaluate(imgs_val, imgs_val, verbose=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# dice_per_fold.append(scores[1] * 10000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# with tf.device(\"/device:CPU:0\"):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "# weight_saver = ModelCheckpoint('pupil', monitor='val_dice_score', save_best_only=True, save_weights_only=True)\n",
    "# decayed_lr = LearningRateScheduler(lambda x: 1e-4 * 0.9 ** x)\n",
    "decayed_lr = LearningRateScheduler(lambda x: 2e-4 * 0.9 ** x)\n",
    "# decayed_lr = LearningRateScheduler(lambda x: 3e-4 * 0.9 ** x)\n",
    "\n",
    "\n",
    "fold_no = 1\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1\n",
    "RANDOM_STATE = SEED\n",
    "dice_per_fold = []\n",
    "loss_per_fold = []\n",
    "acc_per_fold = []\n",
    "# model = pupil2_model().summary()\n",
    "# from sklearn.model_selection import KFold\n",
    "# kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# with mirrored_strategy.scope():\n",
    "\n",
    "# model = build_AE2(img_height=240, img_width=320, filters=32)\n",
    "encoder, decoder, model = build_VAE(img_height=240, img_width=320, filters=32, activation='elu',kernel_init='he_uniform')\n",
    "model.summary()\n",
    "#     model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=[dice_score])\n",
    "model.compile(optimizer=Adam(2e-4),metrics=[dice_score])\n",
    "# model.compile(optimizer=RMSprop(2e-5), loss='binary_crossentropy', metrics=['Accuracy'])\n",
    "# model.compile(optimizer=SGD(learning_rate=0.0001, decay=1e-6, momentum=0.9, nesterov = True), loss='binary_crossentropy', metrics=[dice_score])\n",
    "# model.compile(optimizer=Adam(2e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # model.compile(optimizer=Adam(3e-4), loss='binary_crossentropy', metrics=[dice_score])\n",
    "    # model.compile(optimizer=SGD(2e-4), loss='binary_crossentropy', metrics=[dice_score])\n",
    "\n",
    "# imgs_train = imgs_train[:,:,:,np.newaxis]\n",
    "# imgs_val = imgs_val[:,:,:,np.newaxis]\n",
    "\n",
    "# history = model.fit(imgs_train, imgs_train, validation_data=(imgs_val, imgs_val),batch_size=BATCH_SIZE,epochs=EPOCHS, shuffle=True, verbose=2, callbacks=[decayed_lr])\n",
    "# history = model.fit(imgs_train, imgs_train, validation_data=(imgs_val, imgs_val), batch_size=BATCH_SIZE,epochs=EPOCHS, shuffle=True, verbose=2)\n",
    "history = model.fit(imgs_train, imgs_train, batch_size=BATCH_SIZE,epochs=EPOCHS, shuffle=True, verbose=2)\n",
    "# scores = model.evaluate(imgs_val, imgs_val, verbose=2)\n",
    "# dice_per_fold.append(scores[1] * 10000)\n",
    "#  print(scores)\n",
    "\n",
    "# with tf.device(\"/device:CPU:0\"):\n",
    "# history = model.fit(imgs_train,masks_train,batch_size=5,epochs=50,validation_data=(imgs_val,masks_val), shuffle=True, verbose=2, callbacks=[weight_saver, decayed_lr])\n",
    "# history = model.fit(imgs_train,masks_train,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(imgs_val,masks_val), shuffle=True, verbose=2, callbacks=[weight_saver, decayed_lr])\n",
    "\n",
    "# model.save(f'pupil2_{img_width}x{img_height}_{imgs_lt_original_.shape[0]}_E{EPOCHS}_B{BATCH_SIZE}_R{RANDOM_STATE}_S{round(history.history[\"val_dice_score\"][-1],5)}.h5')\n",
    "model.save(f'VAE1_{img_width}x{img_height}_{imgs_train.shape[0]}_E{EPOCHS}_B{BATCH_SIZE}_R{RANDOM_STATE}_S{round(np.mean(dice_per_fold))}.h5')\n",
    "# model.save(\"pupil3.h5\")\n",
    "# model.save(f'pupil2_{img_width}x{img_height}_{imgs_lt_original.shape[0]}_{EPOCHS}_{BATCH_SIZE}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "range_ = 13\n",
    "predict_size = (240,320)\n",
    "\n",
    "l_x = list(np.linspace(-range_,range_,n))\n",
    "l_y = list(np.linspace(-range_,range_,n))\n",
    "\n",
    "results = []\n",
    "for i in range(len(l_x)):\n",
    "    z_sample = np.array([[l_x[i], l_y[i]]])\n",
    "    img_pred = decoder.predict(z_sample)\n",
    "    img_pred = img_pred.squeeze()\n",
    "    results.append(img_pred)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(len(l_x)):\n",
    "    plt.subplot(n//2,n//2,i+1)\n",
    "    plt.imshow(results[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score_ = history.history['dice_score']\n",
    "val_dice_score = history.history['val_dice_score']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(dice_score_))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, dice_score_, 'bo', label='Training score')\n",
    "plt.plot(epochs, val_dice_score, 'r-', label='Validation score')\n",
    "plt.title('score')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, loss, 'g>', label='Training loss')\n",
    "plt.plot(epochs, val_loss ,'k-', label='Validation loss')\n",
    "plt.title('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
