{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc130e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape: (8640, 240, 320)\n",
      "loading times : 389.7957253456116\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import glob, os, cv2, time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2,3'\n",
    "\n",
    "BASE_TRAIN_PATH = \"./new2_data_sets/train\"\n",
    "BASE_TRAIN_AUGMENTED_PATH = \"./new2_data_sets/train_augmented\"\n",
    "SEED = 4444\n",
    "time_start = time.time()\n",
    "\n",
    "l_train_files = glob.glob(f'{BASE_TRAIN_PATH}/*orig.png')\n",
    "l_mask_files = glob.glob(f'{BASE_TRAIN_PATH}/*mask.png')\n",
    "l_train_aug_files = glob.glob(f'{BASE_TRAIN_AUGMENTED_PATH}/*orig.png')\n",
    "l_mask_aug_files = glob.glob(f'{BASE_TRAIN_AUGMENTED_PATH}/*mask.png')\n",
    "\n",
    "img_trains = np.stack([cv2.imread(i,0) for i in l_train_files])\n",
    "mask_trains = np.stack([cv2.imread(i,0) for i in l_mask_files])\n",
    "img_trains_aug = np.stack([cv2.imread(i,0) for i in l_train_aug_files])\n",
    "mask_trains_aug = np.stack([cv2.imread(i,0) for i in l_mask_aug_files])\n",
    "                \n",
    "imgs = np.concatenate([img_trains, img_trains_aug], axis=0)\n",
    "masks = np.concatenate([mask_trains, mask_trains_aug], axis=0)\n",
    "\n",
    "imgs = imgs / 255.\n",
    "masks = masks / 255.\n",
    "\n",
    "\n",
    "\n",
    "print('train_shape:', imgs.shape)\n",
    "if imgs.shape != masks.shape:\n",
    "    print('wrong train and mask shape')\n",
    "    \n",
    "time_end = time.time()\n",
    "print(\"loading times :\", time_end - time_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f7b3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs_train: (6912, 240, 320) imgs_val: (1728, 240, 320) masks_train: (6912, 240, 320) masks_val: (1728, 240, 320)\n"
     ]
    }
   ],
   "source": [
    "imgs_train, imgs_val, masks_train, masks_val = train_test_split(imgs, masks, test_size=0.2, shuffle=True, random_state=SEED)\n",
    "print('imgs_train:',imgs_train.shape, 'imgs_val:', imgs_val.shape, 'masks_train:', masks_train.shape, 'masks_val:', masks_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32fe49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        \n",
    "        CH = 32\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=CH, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(CH)\n",
    "        self.elu1 = nn.ELU()\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=CH, out_channels=CH*2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(CH*2)\n",
    "        self.elu2 = nn.ELU()\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=CH*2, out_channels=CH*4, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(CH*4)\n",
    "        self.elu3 = nn.ELU()\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=CH*4, out_channels=CH*8, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(CH*8)\n",
    "        self.elu4 = nn.ELU()\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=CH*8, out_channels=CH*16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(CH*16)\n",
    "        self.elu5 = nn.ELU()\n",
    "#         self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(in_channels=(CH*16+CH*8), out_channels=CH*8, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(CH*8)\n",
    "        self.elu6 = nn.ELU()\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(in_channels=(CH*8+CH*4), out_channels=CH*4, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(CH*4)\n",
    "        self.elu7 = nn.ELU()\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(in_channels=(CH*4+CH*2), out_channels=CH*2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(CH*2)\n",
    "        self.elu8 = nn.ELU()\n",
    "        \n",
    "        self.conv9 = nn.Conv2d(in_channels=(CH*2+CH), out_channels=CH, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(CH)\n",
    "        self.elu9 = nn.ELU()\n",
    "        \n",
    "        self.conv10 = nn.Conv2d(in_channels=CH, out_channels=CH, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn10 = nn.BatchNorm2d(CH)\n",
    "        self.elu10 = nn.ELU()\n",
    "        \n",
    "        \n",
    "        self.conv11 = nn.Conv2d(in_channels=CH, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output1 = self.elu1(self.bn1(self.conv1(input)))\n",
    "        pooled1 = self.pool1(output1)\n",
    "        output2 = self.elu2(self.bn2(self.conv2(pooled1)))\n",
    "        pooled2 = self.pool2(output2)\n",
    "        output3 = self.elu3(self.bn3(self.conv3(pooled2)))\n",
    "        pooled3 = self.pool3(output3)\n",
    "        output4 = self.elu4(self.bn4(self.conv4(pooled3)))\n",
    "        pooled4 = self.pool4(output4)\n",
    "        output5 = self.elu5(self.bn5(self.conv5(pooled4)))\n",
    "        \n",
    "#         output6 = np.concatenate([nn.Upsample(scale_factor=2)(output5),output4],axis=-1)\n",
    "        output6 = torch.cat([nn.Upsample(scale_factor=2)(output5), output4], dim=1)\n",
    "        output7 = self.elu6(self.bn6(self.conv6(output6)))\n",
    "#         output8 = np.concatenate([nn.Upsample(scale_factor=2)(output7),output3],axis=-1)\n",
    "        output8 = torch.cat([nn.Upsample(scale_factor=2)(output7), output3], dim=1)\n",
    "        output9 = self.elu7(self.bn7(self.conv7(output8)))\n",
    "#         output10 = np.concatenate([nn.Upsample(scale_factor=2)(output9),output2],axis=-1)\n",
    "        output10 = torch.cat([nn.Upsample(scale_factor=2)(output9), output2], dim=1)\n",
    "        output11 = self.elu8(self.bn8(self.conv8(output10)))\n",
    "#         output12 = np.concatenate([nn.Upsample(scale_factor=2)(output11),output1],axis=-1)\n",
    "        output12 = torch.cat([nn.Upsample(scale_factor=2)(output11), output1], dim=1)\n",
    "        output13 = self.elu9(self.bn9(self.conv9(output12)))\n",
    "        output14 = self.elu10(self.bn10(self.conv10(output13)))\n",
    "        output15 = self.sigmoid(self.conv11(output14))\n",
    "\n",
    "        return output15\n",
    "\n",
    "    \n",
    "\n",
    "def dice_score_(img1, img2):\n",
    "    if not isinstance(img1, numpy.ndarray):\n",
    "        img1 = np.array(img1)\n",
    "    if not isinstance(img2, numpy,ndarray):\n",
    "        img2 = np.array(img2)\n",
    "    img1_f = img1.reshape(1,-1)\n",
    "    img2_f = img2.reshape(1,-1)\n",
    "    intersection = np.sum(img1_f * img2_f)\n",
    "    \n",
    "    return (2. * intersection + np.finfo(float).eps) / (np.sum(ing1_f) + np.sum(ing2_f) + np.finfo(float).eps)\n",
    "\n",
    "\n",
    "def dice_loss_score_Batch(inputs, targets):\n",
    "    iflat = inputs.view(-1)\n",
    "    tflat = targets.view(-1)\n",
    "    \n",
    "    intersection = (iflat * tflat).sum()\n",
    "    dice_score = (2. * intersection + 1e-5) / (iflat.sum() + tflat.sum() + 1e-5)\n",
    "    BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "    dice_loss = BCE + 1-dice_score\n",
    "    return dice_loss, dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7eb74dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "#     classname = m.__class__.__name__\n",
    "    if isinstance(m, (nn.Conv2d, nn.BatchNorm2d, nn.ELU)):\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "        torch.nn.init.kaiming_uniform_(m.weight)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc4ea612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6912, 240, 320, 1)\n",
      "torch.Size([6912, 1, 240, 320])\n",
      "(6912, 1, 240, 320)\n"
     ]
    }
   ],
   "source": [
    "imgs_train_expanded = np.expand_dims(imgs_train, -1)\n",
    "masks_train_expanded = np.expand_dims(masks_train, -1)\n",
    "imgs_val_expanded = np.expand_dims(imgs_val, -1)\n",
    "masks_val_expanded = np.expand_dims(masks_val, -1)\n",
    "print(imgs_train_expanded.shape)\n",
    "\n",
    "imgs_train_trans = np.transpose(imgs_train_expanded, (0,3,1,2))\n",
    "masks_train_trans = np.transpose(masks_train_expanded, (0,3,1,2))\n",
    "imgs_val_trans = np.transpose(imgs_val_expanded, (0,3,1,2))\n",
    "masks_val_trans = np.transpose(masks_val_expanded, (0,3,1,2))\n",
    "\n",
    "imgs_train_tensor = torch.tensor(imgs_train_trans, dtype=torch.float32)\n",
    "masks_train_tensor = torch.tensor(masks_train_trans, dtype=torch.float32)\n",
    "imgs_val_tensor = torch.tensor(imgs_val_trans, dtype=torch.float32)\n",
    "masks_val_tensor = torch.tensor(masks_val_trans, dtype=torch.float32)\n",
    "\n",
    "\n",
    "print(imgs_train_tensor.shape)\n",
    "print(masks_train_trans.shape)\n",
    "\n",
    "# imgs_train_tensor = torch.from_numpy(imgs_train_trans).type(torch.float32)\n",
    "# print(imgs_train_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7de9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class Dice_BCE_loss(nn.Module):\n",
    "#     bce = F.binary_cross_entropy_with_logits(pred, target, reduction='sum')\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(Dice_BCE_loss, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, targets, smooth=1e-5):\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = F.sigmoid(inputs)\n",
    "    \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_score = (2. * intersection + 1e-5)/(inputs.sum() + targets.sum() + 1e-5)\n",
    "        dice_loss = 1 - dice_score\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "    \n",
    "        loss = bce + dice_loss\n",
    "    \n",
    "        return loss, dice_score\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, masks, dtype=torch.float32):\n",
    "        super(MyDataset,self).__init__()\n",
    "        self.imgs = imgs\n",
    "        self.masks = masks\n",
    "        if not torch.is_tensor(self.imgs):\n",
    "            self.imgs = torch.tensor(self.imgs, dtype=torch.float32)\n",
    "        if not torch.is_tensor(self.masks):\n",
    "            self.masks = torch.tensor(self.masks, dtype=torch.float32)\n",
    "        assert(len(self.imgs) == len(self.masks))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {'img': self.imgs[idx], 'mask': self.masks[idx]}\n",
    "    \n",
    "    \n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "    #     if i_batch == 1:\n",
    "\n",
    "    #         print(len(sample_batched['img']))\n",
    "    #         print(sample_batched['img'].shape)\n",
    "    #         print(sample_batched['mask'].shape)\n",
    "    #     if i_batch > max_ibatch:\n",
    "    #         max_ibatch = i_batch\n",
    "        train_start_time = time.time()\n",
    "        X = sample_batched['img'].to('cuda')\n",
    "        y = sample_batched['mask'].to('cuda')\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i_batch % 200 == 0:\n",
    "            loss, current = loss.item(), i_batch * len(X)\n",
    "            d_loss, d_score = dice_loss_score_Batch(pred,y)\n",
    "            print(f\"loss: {loss:.5f}, dice_loss: {d_loss:.5f}, dice_score: {d_score:.5f}  [{current:>4d}/{size:>4d}],time: {time.time()-train_start_time:.5f}\")\n",
    "            \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    global g_dice_score_list\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    test_dice_loss, test_dice_score = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(dataloader):\n",
    "            X = sample_batched['img'].to('cuda')\n",
    "            y = sample_batched['mask'].to('cuda')\n",
    "            pred = model(X)\n",
    "            d_loss, d_score = dice_loss_score_Batch(pred,y)\n",
    "            \n",
    "            test_dice_loss += d_loss\n",
    "            test_dice_score += d_score\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "#             correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_dice_loss /= num_batches\n",
    "    test_dice_score /= num_batches\n",
    "    test_loss /= num_batches\n",
    "    g_dice_score_list.append(test_dice_score)\n",
    "#     correct /= size\n",
    "#     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Ave loss: {test_loss:>8f} \\n\")\n",
    "    print(f\"Test loss: \\n loss: {test_loss:.5f}, dice_loss: {test_dice_loss:.5f}, dice_score: {test_dice_score:.5f}\")\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9f56a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fan in and fan out can not be computed for tensor with fewer than 2 dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20561/2226561325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kwon/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \"\"\"\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kwon/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_20561/3052543183.py\u001b[0m in \u001b[0;36minit_weights\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mELU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kwon/lib/python3.7/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing zero-element tensors is a no-op\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mfan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_correct_fan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m     \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kwon/lib/python3.7/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36m_calculate_correct_fan\u001b[0;34m(tensor, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mode {} not supported, please use one of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_modes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfan_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfan_in\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fan_in'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kwon/lib/python3.7/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36m_calculate_fan_in_and_fan_out\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0mdimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0mnum_input_fmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EPOCH = 70\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "\n",
    "model = Network().to(device)\n",
    "# model.apply(init_weights)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "train_dataset = MyDataset(imgs_train_tensor, masks_train_trans, dtype=torch.float32)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = MyDataset(imgs_val_tensor, masks_val_tensor, dtype=torch.float32)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_time = time.time()\n",
    "global g_dice_score_list\n",
    "g_dice_score_list = []\n",
    "\n",
    "for t in range(EPOCH):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f\"Epoch {t+1}\\n----------------------------\")\n",
    "    \n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "    print(f\"Epoch {t+1} done, time: {time.time()-epoch_start_time:.5f}\")\n",
    "    \n",
    "print(f\"Done!  time:{time.time()-total_time:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39e2f2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8100, 0.8650, 0.9086, 0.9182, 0.9232, 0.9248, 0.9226, 0.9254, 0.9366,\n",
      "        0.9252, 0.9214, 0.9313, 0.9275, 0.9303, 0.9334, 0.9335, 0.9273, 0.9292,\n",
      "        0.9335, 0.9375, 0.9337, 0.9368, 0.9290, 0.9360, 0.9368, 0.9313, 0.9335,\n",
      "        0.9334, 0.9345, 0.9274, 0.9289, 0.9223, 0.9321, 0.9038, 0.9287, 0.9379,\n",
      "        0.9335, 0.9087, 0.9311, 0.9393, 0.9095, 0.9336, 0.9228, 0.9349, 0.9395,\n",
      "        0.9337, 0.9291, 0.9328, 0.9347, 0.9319, 0.9361, 0.9323, 0.9246, 0.9238,\n",
      "        0.9334, 0.9216, 0.9370, 0.9340, 0.9290, 0.9373, 0.9069, 0.9355, 0.9257,\n",
      "        0.9377, 0.9324, 0.9371, 0.9268, 0.9307, 0.9267, 0.9323])\n",
      "average_dice_score : 0.9266654849052429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sm = torch.jit.script(model)\n",
    "# sm.save(\"scripted_model.pt\")\n",
    "\n",
    "MODEL_HEIGHT = 240\n",
    "MODEL_WIDTH = 320\n",
    "\n",
    "average_dice_score = sum(g_dice_score_list)/len(g_dice_score_list)\n",
    "# l_ = [ i.item()[0] for i in g_dice_score_list]\n",
    "a = torch.tensor(g_dice_score_list)\n",
    "print(a)\n",
    "print(f\"average_dice_score : {average_dice_score}\")\n",
    "# example = torch.rand(1,1,MODEL_HEIGHT,MODEL_WIDTH)\n",
    "# traced_script_module = torch.jit.trace(model, example.to('cuda'))\n",
    "# traced_script_module.save(f\"traced_model_E{EPOCH}_B{BATCH_SIZE}_R{SEED}_S{average_dice_score}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7e813d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# params = [i for i in model.parameters()]\n",
    "params = list(model.parameters())\n",
    "print(type(params[0]))\n",
    "print(params[0].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af2de848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Network                                  --\n",
       "├─Conv2d: 1-1                            320\n",
       "├─BatchNorm2d: 1-2                       64\n",
       "├─ELU: 1-3                               --\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Conv2d: 1-5                            18,496\n",
       "├─BatchNorm2d: 1-6                       128\n",
       "├─ELU: 1-7                               --\n",
       "├─MaxPool2d: 1-8                         --\n",
       "├─Conv2d: 1-9                            73,856\n",
       "├─BatchNorm2d: 1-10                      256\n",
       "├─ELU: 1-11                              --\n",
       "├─MaxPool2d: 1-12                        --\n",
       "├─Conv2d: 1-13                           295,168\n",
       "├─BatchNorm2d: 1-14                      512\n",
       "├─ELU: 1-15                              --\n",
       "├─MaxPool2d: 1-16                        --\n",
       "├─Conv2d: 1-17                           1,180,160\n",
       "├─BatchNorm2d: 1-18                      1,024\n",
       "├─ELU: 1-19                              --\n",
       "├─Conv2d: 1-20                           1,769,728\n",
       "├─BatchNorm2d: 1-21                      512\n",
       "├─ELU: 1-22                              --\n",
       "├─Conv2d: 1-23                           442,496\n",
       "├─BatchNorm2d: 1-24                      256\n",
       "├─ELU: 1-25                              --\n",
       "├─Conv2d: 1-26                           110,656\n",
       "├─BatchNorm2d: 1-27                      128\n",
       "├─ELU: 1-28                              --\n",
       "├─Conv2d: 1-29                           27,680\n",
       "├─BatchNorm2d: 1-30                      64\n",
       "├─ELU: 1-31                              --\n",
       "├─Conv2d: 1-32                           9,248\n",
       "├─BatchNorm2d: 1-33                      64\n",
       "├─ELU: 1-34                              --\n",
       "├─Conv2d: 1-35                           33\n",
       "├─Sigmoid: 1-36                          --\n",
       "=================================================================\n",
       "Total params: 3,930,849\n",
       "Trainable params: 3,930,849\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1956e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([0.8100, 0.8650, 0.9086, 0.9182, 0.9232, 0.9248, 0.9226, 0.9254, 0.9366,\n",
    "        0.9252, 0.9214, 0.9313, 0.9275, 0.9303, 0.9334, 0.9335, 0.9273, 0.9292,\n",
    "        0.9335, 0.9375, 0.9337, 0.9368, 0.9290, 0.9360, 0.9368, 0.9313, 0.9335,\n",
    "        0.9334, 0.9345, 0.9274, 0.9289, 0.9223, 0.9321, 0.9038, 0.9287, 0.9379,\n",
    "        0.9335, 0.9087, 0.9311, 0.9393, 0.9095, 0.9336, 0.9228, 0.9349, 0.9395,\n",
    "        0.9337, 0.9291, 0.9328, 0.9347, 0.9319, 0.9361, 0.9323, 0.9246, 0.9238,\n",
    "        0.9334, 0.9216, 0.9370, 0.9340, 0.9290, 0.9373, 0.9069, 0.9355, 0.9257,\n",
    "        0.9377, 0.9324, 0.9371, 0.9268, 0.9307, 0.9267, 0.9323])\n",
    "average_dice_score : 0.9266654849052429"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
